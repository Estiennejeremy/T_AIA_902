{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "# print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4829\n",
      "[[2.53037622e-01 4.96724060e-02 1.21721316e-01 1.25916845e-01]\n",
      " [2.38514974e-02 8.54606885e-03 3.64272004e-03 1.44463196e-01]\n",
      " [3.23364159e-02 4.04902079e-02 1.77472823e-02 5.70839191e-02]\n",
      " [1.40069736e-02 1.09227895e-03 1.66607185e-03 4.84574131e-02]\n",
      " [3.34958018e-01 1.24716014e-02 8.02324793e-02 5.70959645e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.81239968e-01 2.59967707e-05 1.42174426e-04 1.15565720e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.39756754e-02 4.38644773e-02 7.72869982e-02 4.48838242e-01]\n",
      " [1.22755148e-01 6.08100460e-01 1.14649344e-01 1.01373028e-01]\n",
      " [4.73297647e-01 5.28741022e-03 5.78873622e-04 1.92040819e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.23584038e-01 1.46608843e-01 8.60003344e-01 4.90049265e-02]\n",
      " [4.96492570e-01 9.95563454e-01 2.71376788e-01 6.72824240e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "total_episodes = 10000\n",
    "learning_rate = 0.7          \n",
    "max_steps = 99             \n",
    "gamma = 0.95                \n",
    "\n",
    "\n",
    "epsilon = 1.0                 \n",
    "max_epsilon = 1.0             \n",
    "min_epsilon = 0.01           \n",
    "decay_rate = 0.005       \n",
    "\n",
    "rewards = []\n",
    "for episode in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        exp_exp_tradeoff = random.uniform(0, 1)\n",
    "        if exp_exp_tradeoff > epsilon:\n",
    "            action = np.argmax(qtable[state,:])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "        total_rewards += reward\n",
    "        state = new_state\n",
    "        \n",
    "        if done == True: \n",
    "            break\n",
    " \n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "    rewards.append(total_rewards)\n",
    "    \n",
    "\n",
    "print (\"Score: \" +  str(sum(rewards)/total_episodes))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "max_iteration = 100\n",
    "victory = 0\n",
    "steps = []\n",
    "\n",
    "for episode in range(max_iteration):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            # env.render()\n",
    "            if reward == 1:\n",
    "                victory += 1\n",
    "                steps.append(step)\n",
    "            break\n",
    "        state = new_state\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de réussite en mode QLearning :  84.0 %\n",
      "Nombre moyen de pas pour arriver au but :  36.69047619047619\n",
      "Nombre median de pas pour arriver au but :  29.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Pourcentage de réussite en mode QLearning : \", victory / max_iteration * 100, \"%\")\n",
    "print(\"Nombre moyen de pas pour arriver au but : \",np.mean(steps))\n",
    "print(\"Nombre median de pas pour arriver au but : \",np.median(steps))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
